{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ucimlrepo as uci\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting glass dataset\n",
    "data = uci.fetch_ucirepo(id=42)\n",
    "\n",
    "X = data.data.features.values\n",
    "\n",
    "class_maps = {item: i for i, item in enumerate(sorted(data.data.targets[\"Type_of_glass\"].unique()))}\n",
    "y = data.data.targets.values[:, 0]\n",
    "for i, item in enumerate(y):\n",
    "    y[i] = class_maps[item]\n",
    "n_classes = len(class_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = [0.7, 0.1, 0.2]\n",
    "train_X, train_y = [], []\n",
    "val_X, val_y = [], []\n",
    "test_X, test_y = [], []\n",
    "\n",
    "for c in range(n_classes):\n",
    "    class_X = X[y == c]\n",
    "    class_y = y[y == c]\n",
    "    n = len(class_X)\n",
    "    train_index = np.random.permutation(n)\n",
    "    val_index = train_index[int(n * proportion[0]):int(n * (proportion[0] + proportion[1]))]\n",
    "    test_index = train_index[int(n * (proportion[0] + proportion[1])):]\n",
    "    train_index = train_index[:int(n * proportion[0])]\n",
    "    train_X.append(class_X[train_index])\n",
    "    train_y.append(class_y[train_index])\n",
    "    val_X.append(class_X[val_index])\n",
    "    val_y.append(class_y[val_index])\n",
    "    test_X.append(class_X[test_index])\n",
    "    test_y.append(class_y[test_index])\n",
    "    \n",
    "train_X = np.concatenate(train_X, axis=0)\n",
    "train_y = np.concatenate(train_y, axis=0)\n",
    "train_max, train_min = train_X.max(axis=0, keepdims=True), train_X.min(axis=0, keepdims=True)\n",
    "train_X = (train_X - train_min) / (train_max - train_min + 1e-12)\n",
    "val_X = np.concatenate(val_X, axis=0)\n",
    "val_y = np.concatenate(val_y, axis=0)\n",
    "val_X = (val_X - train_min) / (train_max - train_min + 1e-12)\n",
    "test_X = np.concatenate(test_X, axis=0)\n",
    "test_y = np.concatenate(test_y, axis=0)\n",
    "test_X = (test_X - train_min) / (train_max - train_min + 1e-12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 20 46 6 (9,)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), len(val_X), len(test_X), n_classes, test_X[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_probs(num_classes):\n",
    "    probs = np.ones(num_classes)\n",
    "\n",
    "    probs = probs / probs.sum()\n",
    "\n",
    "    return probs\n",
    "\n",
    "def one_hot(arr, num_classes):\n",
    "    out = np.zeros(num_classes)\n",
    "    out[arr] = 1\n",
    "    return out\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def create_bandit_dataset(data, store_folder, num_classes, num_sample=1):\n",
    "\n",
    "    print(\"Pre-processing for num sample = \" + str(num_sample))\n",
    "    train, val, test = data\n",
    "    train_X, train_y = train\n",
    "    val_X, val_y = val\n",
    "    test_X, test_y = test\n",
    "    final_x, final_y, final_actions, final_prop, final_labeled = [], [], [], [], []\n",
    "\n",
    "    for epoch in range(num_sample):\n",
    "        print(range(train_X.shape[0]))\n",
    "        \n",
    "        for point_num in range(train_X.shape[0]):\n",
    "            features = train_X[point_num]\n",
    "            label = train_y[point_num]\n",
    "\n",
    "            probs = get_uniform_probs(num_classes=num_classes)\n",
    "            u = probs.astype(np.float64)\n",
    "            actionvec = np.random.multinomial(1, u / np.sum(u))\n",
    "            action = np.argmax(actionvec)\n",
    "\n",
    "            final_x.append(features)\n",
    "            final_actions.append([action])\n",
    "            final_prop.append(probs)\n",
    "            final_labeled.append(np.array([1.0]))\n",
    "\n",
    "            final_y.append(one_hot(label, num_classes))\n",
    "\n",
    "    train = np.concatenate(\n",
    "        (final_x, final_y, final_prop, final_actions, final_labeled), axis=1\n",
    "    )\n",
    "    train = train[np.random.permutation(len(train))]\n",
    "    final_x, final_y, final_actions, final_prop, final_labeled = [], [], [], [], []\n",
    "        \n",
    "    for point_num in range(val_X.shape[0]):\n",
    "        features = val_X[point_num]\n",
    "        label = val_y[point_num]\n",
    "\n",
    "        probs = get_uniform_probs(num_classes=num_classes)\n",
    "        u = probs.astype(np.float64)\n",
    "        actionvec = np.random.multinomial(1, u / np.sum(u))\n",
    "        action = np.argmax(actionvec)\n",
    "\n",
    "        final_x.append(features)\n",
    "        final_actions.append([action])\n",
    "        final_prop.append(probs)\n",
    "        final_labeled.append(np.array([1.0]))\n",
    "\n",
    "        final_y.append(one_hot(label, num_classes))\n",
    "\n",
    "    val = np.concatenate(\n",
    "        (final_x, final_y, final_prop, final_actions, final_labeled), axis=1\n",
    "    )\n",
    "    val = val[np.random.permutation(len(val))]\n",
    "\n",
    "    final_x, final_y, final_actions, final_prop, final_labeled = [], [], [], [], []\n",
    "    for point_num in range(test_X.shape[0]):\n",
    "        features = test_X[point_num]\n",
    "        label = test_y[point_num]\n",
    "\n",
    "        probs = get_uniform_probs(num_classes=num_classes)\n",
    "        u = probs.astype(np.float64)\n",
    "        actionvec = np.random.multinomial(1, u / np.sum(u))\n",
    "        action = np.argmax(actionvec)\n",
    "\n",
    "        final_x.append(features)\n",
    "        final_actions.append([action])\n",
    "        final_prop.append(probs)\n",
    "\n",
    "        final_y.append(one_hot(label, num_classes))\n",
    "\n",
    "    test = np.concatenate(\n",
    "        (final_x, final_y, final_prop, final_actions), axis=1\n",
    "    )\n",
    "    test = test[np.random.permutation(len(val))]\n",
    "\n",
    "    filename = f\"data/{store_folder}/bandit_data_\"\n",
    "    filename += \"sampled_\" + str(num_sample)\n",
    "    print(\"file name = \", filename)\n",
    "    \n",
    "    save_obj(train, filename + \"_train\")\n",
    "    save_obj(test, filename + \"_test\")\n",
    "    save_obj(val, filename + \"_val\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing for num sample = 1\n",
      "range(0, 148)\n",
      "file name =  data/glass/base/bandit_data_sampled_1\n"
     ]
    }
   ],
   "source": [
    "create_bandit_dataset(((train_X, train_y), (val_X, val_y), (test_X, test_y)), 'glass/base', n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting glass dataset\n",
    "data = uci.fetch_ucirepo(id=59)\n",
    "\n",
    "X = data.data.features.values\n",
    "\n",
    "class_maps = {item: i for i, item in enumerate(sorted(data.data.targets[\"lettr\"].unique()))}\n",
    "y = data.data.targets.values[:, 0]\n",
    "for i, item in enumerate(y):\n",
    "    y[i] = class_maps[item]\n",
    "n_classes = len(class_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = [0.7, 0.1, 0.2]\n",
    "train_X, train_y = [], []\n",
    "val_X, val_y = [], []\n",
    "test_X, test_y = [], []\n",
    "\n",
    "for c in range(n_classes):\n",
    "    class_X = X[y == c]\n",
    "    class_y = y[y == c]\n",
    "    n = len(class_X)\n",
    "    train_index = np.random.permutation(n)\n",
    "    val_index = train_index[int(n * proportion[0]):int(n * (proportion[0] + proportion[1]))]\n",
    "    test_index = train_index[int(n * (proportion[0] + proportion[1])):]\n",
    "    train_index = train_index[:int(n * proportion[0])]\n",
    "    train_X.append(class_X[train_index])\n",
    "    train_y.append(class_y[train_index])\n",
    "    val_X.append(class_X[val_index])\n",
    "    val_y.append(class_y[val_index])\n",
    "    test_X.append(class_X[test_index])\n",
    "    test_y.append(class_y[test_index])\n",
    "    \n",
    "train_X = np.concatenate(train_X, axis=0)\n",
    "train_y = np.concatenate(train_y, axis=0)\n",
    "# train_max, train_min = train_X.max(axis=0, keepdims=True), train_X.min(axis=0, keepdims=True)\n",
    "# train_X = (train_X - train_min) / (train_max - train_min + 1e-12)\n",
    "train_X = train_X / 15\n",
    "val_X = np.concatenate(val_X, axis=0)\n",
    "val_y = np.concatenate(val_y, axis=0)\n",
    "val_X = val_X / 15\n",
    "test_X = np.concatenate(test_X, axis=0)\n",
    "test_y = np.concatenate(test_y, axis=0)\n",
    "test_X = test_X / 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13989 2000 4011 26 (16,)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), len(val_X), len(test_X), n_classes, test_X[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing for num sample = 1\n",
      "range(0, 13989)\n",
      "file name =  data/letter/base/bandit_data_sampled_1\n"
     ]
    }
   ],
   "source": [
    "create_bandit_dataset(((train_X, train_y), (val_X, val_y), (test_X, test_y)), 'letter/base', n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optdigits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting glass dataset\n",
    "data = uci.fetch_ucirepo(id=80)\n",
    "\n",
    "X = data.data.features.values\n",
    "\n",
    "class_maps = {item: i for i, item in enumerate(sorted(data.data.targets[\"class\"].unique()))}\n",
    "y = data.data.targets.values[:, 0]\n",
    "for i, item in enumerate(y):\n",
    "    y[i] = class_maps[item]\n",
    "n_classes = len(class_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, (5620, 64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = [0.7, 0.1, 0.2]\n",
    "train_X, train_y = [], []\n",
    "val_X, val_y = [], []\n",
    "test_X, test_y = [], []\n",
    "\n",
    "for c in range(n_classes):\n",
    "    class_X = X[y == c]\n",
    "    class_y = y[y == c]\n",
    "    n = len(class_X)\n",
    "    train_index = np.random.permutation(n)\n",
    "    val_index = train_index[int(n * proportion[0]):int(n * (proportion[0] + proportion[1]))]\n",
    "    test_index = train_index[int(n * (proportion[0] + proportion[1])):]\n",
    "    train_index = train_index[:int(n * proportion[0])]\n",
    "    train_X.append(class_X[train_index])\n",
    "    train_y.append(class_y[train_index])\n",
    "    val_X.append(class_X[val_index])\n",
    "    val_y.append(class_y[val_index])\n",
    "    test_X.append(class_X[test_index])\n",
    "    test_y.append(class_y[test_index])\n",
    "    \n",
    "train_X = np.concatenate(train_X, axis=0)\n",
    "train_y = np.concatenate(train_y, axis=0)\n",
    "train_max, train_min = train_X.max(axis=0, keepdims=True), train_X.min(axis=0, keepdims=True)\n",
    "train_X = (train_X - train_min) / (train_max - train_min + 1e-12)\n",
    "val_X = np.concatenate(val_X, axis=0)\n",
    "val_y = np.concatenate(val_y, axis=0)\n",
    "val_X = (val_X - train_min) / (train_max - train_min + 1e-12)\n",
    "test_X = np.concatenate(test_X, axis=0)\n",
    "test_y = np.concatenate(test_y, axis=0)\n",
    "test_X = (test_X - train_min) / (train_max - train_min + 1e-12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3928 563 1129 10 (64,)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), len(val_X), len(test_X), n_classes, test_X[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing for num sample = 1\n",
      "range(0, 3928)\n",
      "file name =  data/optdigits/base/bandit_data_sampled_1\n"
     ]
    }
   ],
   "source": [
    "create_bandit_dataset(((train_X, train_y), (val_X, val_y), (test_X, test_y)), 'optdigits/base', n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yeast Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting glass dataset\n",
    "data = uci.fetch_ucirepo(id=110)\n",
    "\n",
    "X = data.data.features.values\n",
    "\n",
    "class_maps = {item: i for i, item in enumerate(sorted(data.data.targets[\"localization_site\"].unique()))}\n",
    "y = data.data.targets.values[:, 0]\n",
    "for i, item in enumerate(y):\n",
    "    y[i] = class_maps[item]\n",
    "n_classes = len(class_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, (1484, 8))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion = [0.7, 0.1, 0.2]\n",
    "train_X, train_y = [], []\n",
    "val_X, val_y = [], []\n",
    "test_X, test_y = [], []\n",
    "\n",
    "for c in range(n_classes):\n",
    "    class_X = X[y == c]\n",
    "    class_y = y[y == c]\n",
    "    n = len(class_X)\n",
    "    train_index = np.random.permutation(n)\n",
    "    val_index = train_index[int(n * proportion[0]):int(n * (proportion[0] + proportion[1]))]\n",
    "    test_index = train_index[int(n * (proportion[0] + proportion[1])):]\n",
    "    train_index = train_index[:int(n * proportion[0])]\n",
    "    train_X.append(class_X[train_index])\n",
    "    train_y.append(class_y[train_index])\n",
    "    val_X.append(class_X[val_index])\n",
    "    val_y.append(class_y[val_index])\n",
    "    test_X.append(class_X[test_index])\n",
    "    test_y.append(class_y[test_index])\n",
    "    \n",
    "train_X = np.concatenate(train_X, axis=0)\n",
    "train_y = np.concatenate(train_y, axis=0)\n",
    "train_max, train_min = train_X.max(axis=0, keepdims=True), train_X.min(axis=0, keepdims=True)\n",
    "train_X = (train_X - train_min) / (train_max - train_min + 1e-12)\n",
    "val_X = np.concatenate(val_X, axis=0)\n",
    "val_y = np.concatenate(val_y, axis=0)\n",
    "val_X = (val_X - train_min) / (train_max - train_min + 1e-12)\n",
    "test_X = np.concatenate(test_X, axis=0)\n",
    "test_y = np.concatenate(test_y, axis=0)\n",
    "test_X = (test_X - train_min) / (train_max - train_min + 1e-12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035 146 303 10 (8,)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X), len(val_X), len(test_X), n_classes, test_X[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing for num sample = 1\n",
      "range(0, 1035)\n",
      "file name =  data/yeast/base/bandit_data_sampled_1\n"
     ]
    }
   ],
   "source": [
    "create_bandit_dataset(((train_X, train_y), (val_X, val_y), (test_X, test_y)), 'yeast/base', n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
