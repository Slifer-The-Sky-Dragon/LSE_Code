template: true
optimizer: 'SGD'
dataset: 'opd'
num_sample: 0.6a
lr: 0.01
epochs: 300
batch_size: 256
batch_log_interval: 50
train_limit: 500_000
exs_alpha: 1
lamda: 0
experiment: 
  name: 'full_exponential_smoothing_bandit_feedback'
  n_exp: 3
  n_trials: 1
  feedback: 'bandit'
  regularizers: null